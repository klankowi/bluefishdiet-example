---
title: "SST methods"
author: "Sarah Gaichas"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_fold: hide
link-citations: yes
csl: ices-journal-of-marine-science.csl
bibliography: FishDiet_EcoIndicators.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)

library(tidyverse)
library(here)
library(DT)
library(FishStatsUtils)
library(sf)
library(raster)


```

## SST source

We are using the same source data as SOE, at https://psl.noaa.gov/data/gridded/data.noaa.oisst.v2.highres.html 

"NOAA High Resolution SST data provided by the NOAA/OAR/ESRL PSL, Boulder, Colorado, USA, from their Web site" [above]

Initial pull code was kindly provided by Kim Bastille
https://github.com/kimberly-bastille/ecopull/blob/main/.github/workflows/pull_satellite_data.yml
pulling daily gridded SST for each year 1985-2021 using her code starting line 260

I am also using Kim's nc_to_raster function for NEUS shelf from https://github.com/kimberly-bastille/ecopull/blob/main/R/utils.R (below)

```{r}
#' Convert netcdf to raster
#'
#' This function converts a netcdf object to a raster object
#' @param nc The nc file path
#' @param varname The name of the variable to convert to a raster
#' @param extent The latitude and longitude range the data should have, of the form c(xmin, xmax, ymin, ymax). Defaults to `c(0, 360, -90, 90)`
#' @param crop An extent object to use to crop data. Defaults to `raster::extent(280, 300, 30, 50)` (Northeast US)
#' @param show_images Boolean. Whether to display images of the data. Useful to check if cropping is occurring correctly.
#' @return A raster brick
#' @importFrom magrittr %>%
#' @export

nc_to_raster <- function(nc,
                         varname,
                         extent = c(0, 360, -90, 90),
                         crop = raster::extent(280, 300, 30, 50),
                         show_images = FALSE) {
  
  message("Reading .nc as brick...")
  
  r <- raster::brick(nc, varname = varname)
  
  message("Setting CRS...")
  raster::crs(r) <- "+proj=longlat +lat_1=35 +lat_2=45 +lat_0=40 +lon_0=-77 +x_0=0 +y_0=0 +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"
  
  # not sure if this is necessary?
  raster::extent(r) <- raster::extent(extent)
  
  if(show_images){
    par(mfrow = c(1,2))
    raster::plot(r, 1, sub = "Full dataset")
  }
  
  message("Cropping data...")
  ne_data <- raster::crop(r, crop)
  #ne_data <- raster::rotate(ne_data) add here for future pulls
  
  if(show_images){
    raster::plot(ne_data, 1, sub = "Cropped dataset")
    par(mfrow = c(1,1))
  }
  
  message("Done!")
  
  return(ne_data)
}
```

I pulled the data and stored NEUS rasters using scripts in `pull_OISST.R` copied below, which was adapted from https://github.com/kimberly-bastille/ecopull/blob/main/.github/workflows/run_recent_years.yaml to work with the `nc_to_raster` function above.

Note that this times out and had to be rerun for whatever years it didn't get to. Probably my internet connection... works eventually.

```{r, eval=FALSE}
varname <- "sst"

years <- 1985:2021
for(i in years) {
  name <- paste0(i, ".nc")
  dir.create(here::here("data-raw","gridded", "sst_data"), recursive = TRUE)
  filename <- here::here("data-raw","gridded", "sst_data", paste0("test_", i, ".grd"))
  url <- paste0("https://downloads.psl.noaa.gov/Datasets/noaa.oisst.v2.highres/sst.day.mean.", i, ".v2.nc")
  download.file(url, destfile = name)
  
  text <- knitr::knit_expand(text = "test_{{year}} <- nc_to_raster(nc = name, varname = varname)
                                     raster::writeRaster(test_{{year}}, filename = filename, overwrite=TRUE)",
                             year = i)
  print(text)
  try(eval(parse(text = text)))
  unlink(name) # remove nc file to save space
  print(paste("finished",i))
}
```

The plan is to match each survey date and location with the daily SST at that location (or nearest location). Then the SST data will be integrated with the input data.

An alternative is to overlay survey stations on the daily SST raster and get the SST value that way. 

This is a function to make rasters into data frame for merge with survey
needs long df with date split to year, month, day, lat, lon, sst
crop to NEUS extent
conversion to df from https://towardsdatascience.com/transforming-spatial-data-to-tabular-data-in-r-4dab139f311f

```{r}
raster_to_sstdf <- function(brick,
                            rotate=TRUE){
  
  if(rotate) brick_r <- raster::rotate(brick)
  brick_r <- raster::crop(brick_r, raster::extent(-77,-65,35,45))
  sstdf <- as.data.frame(raster::rasterToPoints(brick_r, spatial = TRUE))
  sstdf <- sstdf %>%
    dplyr::rename(Lon = x,
                  Lat = y) %>%
    tidyr::pivot_longer(cols = starts_with("X"),
                        names_to = c("year", "month", "day"),
                        names_prefix = "X",
                        names_sep = "\\.",
                        values_to = "sst",
    )
  return(sstdf)
}
```

Note this is working with the rasters in memory from running the download script, could read in files instead in name statement. 

```{r, eval=FALSE}
years <- 1985:2021
for(i in years) {
  name <- get(paste0("test_",i))
  filename <- here::here("data-raw","gridded", "sst_data", paste0("sst", i, ".rds"))
  text <- knitr::knit_expand(text = "sst{{year}} <- raster_to_sstdf(brick = name)
                                     saveRDS(sst{{year}}, filename)",
                             year = i)
  print(text)
  try(eval(parse(text = text)))
}
```

Plot to see if the dataframes of SST look reasonable

```{r}
#visualize
sst2021 <- readRDS(here("data-raw/gridded/sst_data/sst2021.rds"))

oneday <- sst2021[sst2021$month=="07" & sst2021$day=="04",] 

jan15 <- sst2021[sst2021$month=="01" & sst2021$day=="15",] 

mar15 <- sst2021[sst2021$month=="03" & sst2021$day=="15",]

may15 <- sst2021[sst2021$month=="05" & sst2021$day=="15",]

jul15 <- sst2021[sst2021$month=="07" & sst2021$day=="15",]

sep15 <- sst2021[sst2021$month=="09" & sst2021$day=="15",]

nov15 <- sst2021[sst2021$month=="11" & sst2021$day=="15",]

dailysstplot <- function(oneday){
  ggplot() +
    geom_tile(data = oneday, aes(x = Lon, y = Lat, fill = sst)) +
    geom_sf(data = ecodata::coast) +
    geom_point(data = northwest_atlantic_grid, aes(x = Lon, y = Lat), size=0.05, alpha=0.1) +
    scale_fill_gradientn(name = "Temp C",
                         limits = c(0.5, 31),
                         colours = c(scales::muted("blue"), "white",
                                     scales::muted("red"), "black")) +
    coord_sf(xlim = c(-77, -65), ylim = c(35, 45)) + 
    ggtitle(paste("SST, mm dd yyyy:", unique(oneday$month),
                   unique(oneday$day), unique(oneday$year), sep = " "))
}

#dailysstplot(oneday)

#par(mfrow=c(2,3))
dailysstplot(jan15)
dailysstplot(mar15)
dailysstplot(may15)
dailysstplot(jul15)
dailysstplot(sep15)
dailysstplot(nov15)
```

Next, find set of unique year month day from diet dataset (including NEAMAP) to find the equivalent times in the SST data. BUT I didn't retain month and day in this dataset. The station id could be matched back to the full dataset instead.

This shows the work of getting the dataset with day, month, and recorded surface temp for NEAMAP along with some quality assurance, but the dataset has been saved and this code is not run live.

```{r, eval=FALSE}
bluepyagg_stn_all <- readRDS(here("fhdat/bluepyagg_stn_all.rds"))

diethauls <- bluepyagg_stn_all %>%
  dplyr::select(id, declat, declon)

# date already included in tow id for NEAMAP--nope, need this
# need allfh to get the day and month for NEFSC trawl data
load(url("https://github.com/Laurels1/Condition/raw/master/data/allfh.RData"))

NEFSCstations <- allfh %>%
  dplyr::mutate(id = paste0(cruise6, "_", station),
         year = as.numeric(year),
         month = as.numeric(month),
         day = as.numeric(day),
         declon = -declon) %>%
  dplyr::select(id, year, month, day, declat, declon) %>%
  dplyr::distinct()

#diethauls <- left_join(diethauls, NEFSCstations)

```

Still need month and day columns for NEAMAP; got 'em fast thanks to Jim Gartland!

```{r, eval=FALSE}

NEAMAPstationSST <- read.csv(here("fhdat/NEAMAP SST_2007_2021.csv"))

NEAMAPstations <- NEAMAPstationSST %>%
  dplyr::mutate(id = station,
         year = as.numeric(year),
         month = as.numeric(month),
         day = as.numeric(day),
         declat = latitude,
         declon = longitude) %>%
  dplyr::select(id, year, month, day, declat, declon) %>%
  dplyr::distinct()

```

Now combine NEAMAP and NEFSC and join with diet stations

```{r, eval=FALSE}

Allstations <- bind_rows(NEFSCstations, NEAMAPstations)

diethauls <- left_join(diethauls, Allstations)

```

Check NA dates: 5 hauls in allfh have no station data, one made it to the bluefish diet database (201202_389) because it has piscivores sampled (cod) but no bluefish prey. It has no spatial information so has not been included in analysis, and it is on the Scotial Shelf.

```{r, eval=FALSE}

badhaulNEFSC <- as.data.frame(filter(Allstations, is.na(month))) %>%
  tidyr::separate(id, c("cruise6", "station")) %>%
  dplyr::select(cruise6, station) %>%
  dplyr::mutate(across(where(is.character), as.integer))

badhaulNEFSCFH <- badhaulNEFSC %>%
  left_join(allfh)

badhaulall <- as.data.frame(filter(diethauls, is.na(month)))

badhaulNEFSCFH%>%filter(station %in% 389)

```

NEAMAP has station data; 34 records don't merge because latitude is different at the 8th decimal place. Jim Gartland confirmed that this is due to conversions between different software during data processing. We will use the version of latitude that is recommended by the NEAMAP team, whch is the original entries in the food habits data.

```{r, eval=FALSE}

mismatchNEAMAP <- badhaulall %>%
  dplyr::filter(!is.na(declat)) %>%
  dplyr::select(id)

mismatchNEAMAP

mismatchNEAMAPstn <- mismatchNEAMAP %>%
  left_join(NEAMAPstations)

print(mismatchNEAMAPstn$declat, digits=16)

mismatchNEAMAPfh <- mismatchNEAMAP %>%
  left_join(bluepyagg_stn_all)

print(mismatchNEAMAPfh$declat, digits=16)

```

Since we know the NEAMAP lat and lon in the original diet dataset are correct, we will merge only the station id number, day, month, year, and surface temperature into the diet dataset to avoid the mismatch with 34 stations. We will also add the SST field as surftemp to be in the same column as in-situ measured temperature for the NEFSC survey.

```{r, eval=FALSE}

NEAMAPstations <- NEAMAPstationSST %>%
  dplyr::mutate(id = station,
         year = as.numeric(year),
         month = as.numeric(month),
         day = as.numeric(day)) %>%
  dplyr::select(id, year, month, day) %>%
  dplyr::distinct()

# remake diethauls
diethauls <- bluepyagg_stn_all %>%
  dplyr::select(id, declat, declon)

NEFSCstations <- dplyr::select(NEFSCstations, c(-declat, -declon))

Allstations <- bind_rows(NEFSCstations, NEAMAPstations)

#station id, lat lon, year month day
diethauls <- left_join(diethauls, Allstations)

#add year month day to diet data
bluepyagg_stn_all <- left_join(bluepyagg_stn_all, diethauls)

# add NEAMAP SST to surftemp field
NEAMAPidSST <- NEAMAPstationSST %>%
  mutate(id = station) %>%
  dplyr::select(id, SST)
  
bluepyagg_stn_all <- left_join(bluepyagg_stn_all, NEAMAPidSST, by="id") %>%
  mutate(surftemp = coalesce(surftemp, SST)) %>%
  dplyr::select(-SST)

# save merged dataset with day, month, and NEAMAP surftemp, same name
saveRDS(bluepyagg_stn_all, here("fhdat/bluepyagg_stn_all.rds"))
```

In this new dataset, the majority of missing surftemp observations are from NEFSC (3073), but thre are still 45 NEAMAP stations missing surftemp as well that we can fill with the OISST temperature.

Now to get OISST data for each day/month/year/station location.

Process: 

for each year, 
read in raster brick file or dataframe for that year
find dates with survey hauls
get SST for survey haul date and position (nearest neighbor)
save year month day position OISST
close the raster brick (df)
bind_rows into single dataframe over all years
merge with diet dataframe

```{r}
#read in diet data with month day fields
bluepyagg_stn_all <- readRDS(here("fhdat/bluepyagg_stn_all.rds"))

#list of SST dataframes
SSTdfs <- list.files(here("data-raw/gridded/sst_data/"), pattern = "*.rds")

dietwithOISST <- tibble()

library(nngeo)

for(df in SSTdfs){
  sstdf <- readRDS(paste0(here("data-raw/gridded/sst_data/", df)))
  yrdietOISST <- inner_join(bluepyagg_stn_all, sstdf, by=c(month, day)) %>%
    #nearest neighbor match to lat lon
    st_nn
                   
}



```


